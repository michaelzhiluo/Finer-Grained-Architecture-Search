7 papers a week

Gradient-based Hyperparameter Optimization through Reversible Learning
https://arxiv.org/abs/1502.03492
    -Most papers that perform gradient based hyperparmaeter optimization stores all the weights w1, ... w_t to find
    gradient for hyperparameters at time step 1
    -This paper finds a way via momentum descent to find gradients w.r.t hyperparemters in O(T) time with constant memory proportional
    to number of weights, not W*T. 
    -Lots of cool applications in the paper (you can treat initialized weights as a hyperparameter!)
    -CON: to improve hyperparameters, you gotta do a bit of training than go from time T to time 1 to obtain gradient for hyperparameters 
    at that timestep
    -Weightsharing? Between interations of meta improvements?

Hyperparameter optimization with approximate gradient
https://arxiv.org/abs/1602.02355
    -Pretty sure DART's main inspiration was off this paper, the algorithms are very very similar
    -Same idea where you hyperparameter and parameter updating are done in a bi-level optimization like in DART


https://arxiv.org/abs/1608.06993
https://arxiv.org/abs/1711.05611

Winning Ticket Hypothesis
https://arxiv.org/abs/1803.03635
    - Algorithm:
        -Initialize Network with weights, w0
        -Loop:
            -Train till convergence
            -Prune smallest weights
            -Take the pruned network and reinitialize the remaining weights to w0
    - Larger networks have a larger combination of "winning tickets" (subnetworks that have a good combination during 
    initialization w0 that result in high accuracy), hence the idea of pruning
    -When randomly reinitialized or rearranged, winning tickets perform far worse than the original network, meaning neither structure nor
    initialization alone is responsible for a winning ticketâ€™s success.
    - how do they parameterize the pruned network? do they zero out the weights?

DART Architecture Search
https://arxiv.org/abs/1806.09055
    -Optimizes based on cell, not entire network (convolutional or recurrent cell like LSTM or GRU)
    -How Their Cell model works
        -Imagine the cell as a dag with nodes
            -2 nodes for input (from previous 2 convolutional layers) and 1 node for output
            -Cell also contains n intermediary nodes, x1, x2, x3, .... xn
            -The edge connecting between two nodes is a mathematical operation (conv, zero, etc)
                -M mathematical operations (could be anything wtih trainable weights)
            -There are LOTS of edges
                -Both input nodes are connected to x1, ... xn
                -All intermediary nodes are connected to output node
                -For all i<j, node x_i connects to x_j
                -Between any two nodes with a valid connection, there are M edges, each of which is a mathematical operation
                    -IMPORTANT: The output of the M edges is a weighted softmaxed sum of all M mathematical operations
                        -Adds another set of weights, alpha_(i,j), to represent how much each of those M mathemtical operations 
                        should be weighted
    -This becomes a cool dual optimization problem:
        -Given a fixed alpha_(i,j), optimize weights over training set
        -Given fixed weights, optimize alpha over validation set
    -The above optimiztion problem is expensive, hence the DART algorithm:
        -For each interation of training over weights w, update weights over training set, then update alpha over validation set
            -Different than finding optimal w*, then updating alpha to alpha', then finding optimal w**, etc.
        -Another caveat is that they choose the largest alpha as the only connection between nodes after training

Stackable NN Modules
https://arxiv.org/abs/1807.08556
-Don't see the weight sharing in this example
